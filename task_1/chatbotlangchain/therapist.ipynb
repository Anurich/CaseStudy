{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    In oder to build the therapist I can think of two solution.\n",
      "    1. Given the query or speech by user A: we can try to understand the tone or emotion in the speech or text, for that we can use either LLMs, to\n",
      "    find the emotion or can fine-tune our own emotion detection (which is done by me in the emotion detection folder). \n",
      "    2. Once we know if person is suffering from anger management issue or depression we can perform the chatting \n",
      "    with the corresponding Agent type: for example Agent therapist expert in depression handling, or Agent therapise expert in anger handling.\n",
      "    3. We can also use the same Agent expert in both. \n",
      "\n",
      "    4. Another approach could be find the emotion of a person, based on speech or text. and than pull out the correspoinding informations based on\n",
      "    the certain problem for example if person suffering from anger issue we will have the dataset for handling the anger issue created or framed \n",
      "    by actual therapist, than we can create a RAG system which will help us answer the user query. \n",
      "\n",
      "    5. To handle the Hallucination we can grade the responses generated from LLMs. \n",
      "    6. We can also handle the case when the agent unable to answer in that case we can move to search online from internet to generate the \n",
      "    answer. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "    In oder to build the therapist I can think of two solution.\n",
    "    1. Given the query or speech by user A: we can try to understand the tone or emotion in the speech or text, for that we can use either LLMs, to\n",
    "    find the emotion or can fine-tune our own emotion detection (which is done by me in the emotion detection folder). \n",
    "    2. Once we know if person is suffering from anger management issue or depression we can perform the chatting \n",
    "    with the corresponding Agent type: for example Agent therapist expert in depression handling, or Agent therapise expert in anger handling.\n",
    "    3. We can also use the same Agent expert in both. \n",
    "\n",
    "    4. Another approach could be find the emotion of a person, based on speech or text. and than pull out the correspoinding informations based on\n",
    "    the certain problem for example if person suffering from anger issue we will have the dataset for handling the anger issue created or framed \n",
    "    by actual therapist, than we can create a RAG system which will help us answer the user query. \n",
    "\n",
    "    5. To handle the Hallucination we can grade the responses generated from LLMs. \n",
    "    6. We can also handle the case when the agent unable to answer in that case we can move to search online from internet to generate the \n",
    "    answer. \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniforge3/envs/env-langchain/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "data = datasets.load_dataset(\"Amod/mental_health_counseling_conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responses = []\n",
    "for train in data[\"train\"]:\n",
    "    all_responses.append(train[\"Response\"])\n",
    "mental_health = \" \".join(all_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use langgraph to tackle this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"mistral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the two different retriver\n",
    "* For anger.\n",
    "* For depression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "doc = Document(page_content=mental_health,metadata={\"source\": \"local\"})\n",
    "# retreival system \n",
    "embeddings = GPT4AllEmbeddings()\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=256, chunk_overlap=0\n",
    ")\n",
    "\n",
    "splitted_docs = text_splitter.split_documents([doc])\n",
    "# let's compute the embeddings \n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splitted_docs,\n",
    "    collection_name=\"rag-therapist-depression\",\n",
    "    embedding=GPT4AllEmbeddings(),\n",
    ")\n",
    "retriever_depression = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\"https://www.apa.org/topics/anger/control\"]\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "\n",
    "embeddings = GPT4AllEmbeddings()\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=256, chunk_overlap=0\n",
    ")\n",
    "splitted_docs = text_splitter.split_documents(docs_list)\n",
    "# let's compute the embeddings \n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splitted_docs,\n",
    "    collection_name=\"rag-therapist-anger\",\n",
    "    embedding=GPT4AllEmbeddings(),\n",
    ")\n",
    "retriever_angry= vectorstore.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_to_retriever = {\n",
    "    \"depression\":  retriever_depression,\n",
    "    \"angry\": retriever_angry\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emotion': 'angry'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the type of emotion \n",
    "# we can also use the model i have trained inside the emotion detection folder\n",
    "# this model can be used as a tool, we can create a structured tool to use that model which return the type of emotion.\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "# we need to udnerstand what kind of emotion is in query\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "prompt=\"\"\"\n",
    "    Your an expert in understanding the emotion in the query, provided to you by the user. \n",
    "    Your task is to understand the query and assign the emotion based on your semantic understanding, the labels that can be assigned to the queries are:\n",
    "    1. angry\n",
    "    2. depression\n",
    "    3. otherwise (it could be anxious, happy, etc)\n",
    "    Do not generate any other emotion apart from what is being suggested to you.\n",
    "    Query to assign type of emotion: {Query}, \n",
    "    Provide the respose in Json format so key is going to be emotion and value is type of emotion, do not provide any other kind of explaination.\n",
    "\"\"\"\n",
    "template = PromptTemplate.from_template(prompt)\n",
    "emotion_detection = template | llm | JsonOutputParser()\n",
    "emotion_detection.invoke({\"Query\": \"Shit hit the fence i need money!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an LLM based Agent which can handled for the cases where person don't know \n",
    "# if it's depressed or angry like the person has no information about it's condition\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import ConversationChain\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "PROMPT = \"\"\" As a trained psychologist specialized in emotional well-being, your task is to support individuals facing various challenges in life, including but not limited to:\n",
    "\n",
    "1. Anger Management\n",
    "2. Depression\n",
    "3. Relationship Breakups\n",
    "4. Anxiety\n",
    "5. Family Conflicts\n",
    "\n",
    "The aim is to be a compassionate companion on this journey towards healing and self-discovery, providing practical solutions to navigate these difficult times.\n",
    "\n",
    "When addressing concerns, emphasis will be placed on:\n",
    "\n",
    "- Meditation and mindfulness practices for mental clarity\n",
    "- Spirituality for inner peace and resilience\n",
    "- Focusing on factors within one's control to foster happiness and reduce worry\n",
    "\n",
    "if the input from the user is not related to above discussed point you can do the normal conversation. Make sure response is not too long, and it should be precise.\n",
    "\n",
    "You will be provided with:\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI Assistance:\n",
    "\"\"\"\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    prompt = PromptTemplate(input_variables=[\"history\",\"input\"],template=PROMPT),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hello',\n",
       " 'history': '',\n",
       " 'response': \" Hello! I'm here to support you in various aspects of emotional well-being. If you're dealing with anger management, depression, relationship issues, anxiety, or family conflicts, please feel free to share and I'll do my best to help. We can explore meditation and mindfulness practices for mental clarity, spirituality for inner peace, and focusing on factors within your control to foster happiness. How may I assist you today?\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke({\"input\":\"hello\",\"history\":[\"\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"\n",
    "    Your are psychologist your job is to looked at people personal problem and try to provide them with solution, Solution you provid is\n",
    "    based on the history, context provided to you by the user. You try to find the solution provided all the information to you by the user.\n",
    "    If solution is not present within the context, and chat history, you than suggest the solution from your end following some key points:\n",
    "    1. Happiness\n",
    "    2. Spirituality\n",
    "    3. Confidence\n",
    "    4. Meaning of life.\n",
    "    History: {chat_history}\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Question: {question}\n",
    "    Answer: \n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "rag_chain = prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I propose an approach to check for an hallucination of LLMs,\n",
    "1. I am using RAG for two types of emotions, depression and angry, So i am trying to find the relative documents based on question.\n",
    "2. Now when i find the answer in those documents, I try to grade those document using hallucination_grader, which gives score as yes or no.\n",
    "3. if yes we basically end the cycle, and if no i use chat_with_agent.\n",
    "\"\"\"\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an answer is grounded in / supported by a set of facts. \\n \n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the answer is grounded in / supported by a set of facts. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_community.document_compressors.llmlingua_filter import LLMLinguaCompressor\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain import hub\n",
    "\n",
    "compressor = LLMLinguaCompressor(model_name=\"openai-community/gpt2\", device_map=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    response: str\n",
    "    documents: List[str]\n",
    "    chat_history_chat_agent: List[str]=[]\n",
    "    chat_history: List[str]=[]\n",
    "    \n",
    "# get the emotion of the queries by the user\n",
    "def getEmotions(state):\n",
    "    question = state[\"question\"]\n",
    "    type_of_emotion = emotion_detection.invoke({\"Query\": question})\n",
    "\n",
    "    print(type_of_emotion)\n",
    "    if type_of_emotion[\"emotion\"] == \"angry\":\n",
    "        # we need to perform one type of retrieval which take care of angry part\n",
    "        return \"angry\"\n",
    "    elif type_of_emotion[\"emotion\"] == \"depression\":\n",
    "        # we need to route to another type of retreival \n",
    "        return \"depression\"\n",
    "    else:\n",
    "        return \"chatwithagent\"\n",
    "\n",
    "def depression_retreival(state):\n",
    "    question= state[\"question\"]\n",
    "    # given these documents we can also do much more than just retreiving the data\n",
    "    # we can perform contextual compression \n",
    "    # we can do re-ranking of the documents\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor, base_retriever=retriever_depression\n",
    "        )\n",
    "    compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "    history = [doc.page_content for doc in compressed_docs]\n",
    "    return {\"question\": question, \"documents\": compressed_docs, \"documents\": history}\n",
    "\n",
    "\n",
    "def anger_retreival(state):\n",
    "    question= state[\"question\"]\n",
    "    # given these documents we can also do much more than just retreiving the data\n",
    "    # we can perform contextual compression \n",
    "    # we can do re-ranking of the documents\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor, base_retriever=retriever_angry\n",
    "        )\n",
    "    compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "    history = [doc.page_content for doc in compressed_docs]\n",
    "    return {\"question\": question, \"documents\": history}\n",
    "\n",
    "def chat_with_agent(state):\n",
    "    question = state[\"question\"]\n",
    "    chat_history_chat_agent = state[\"chat_history_chat_agent\"]\n",
    "    if chat_history_chat_agent == None:\n",
    "        chat_history_chat_agent = [\"\"]\n",
    "    response = conversation.invoke({\"input\": question, \"history\": chat_history_chat_agent })\n",
    "\n",
    "    if len(chat_history_chat_agent) > 10:\n",
    "        del chat_history_chat_agent[0]\n",
    "        chat_history_chat_agent.append(response[\"history\"])\n",
    "    else:\n",
    "        chat_history_chat_agent.append(response[\"history\"])\n",
    "\n",
    "    return {\"question\": question, \"response\": response[\"response\"], \"chat_history_chat_agent\":chat_history_chat_agent}\n",
    "\n",
    "def generate_response(state):\n",
    "    question = state[\"question\"]\n",
    "    context = state[\"documents\"]\n",
    "    chat_history = state[\"chat_history\"]\n",
    "    response = rag_chain.invoke({\"question\": question, \"context\": context, \"chat_history\": chat_history})\n",
    "    if chat_history == None:\n",
    "        chat_history = [response]\n",
    "    elif len(chat_history) > 10:\n",
    "        del chat_history[0]\n",
    "        chat_history.append(response)\n",
    "    \n",
    "    return {\"question\": question, \"response\": response, \"chat_history\": chat_history}\n",
    "\n",
    "\n",
    "def check_hallucination(state):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    response = hallucination_grader.invoke({\"generation\": question, \"documents\": documents})\n",
    "    print(response)\n",
    "    if response[\"score\"] == \"yes\":\n",
    "        return \"not useful\"\n",
    "    else:\n",
    "        return \"chat_with_agent\"\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"depression_retreival\", depression_retreival)\n",
    "workflow.add_node(\"anger_retreival\", anger_retreival)\n",
    "workflow.add_node(\"chat_with_agent\", chat_with_agent)\n",
    "workflow.add_node(\"generate_response\",generate_response)\n",
    "\n",
    "workflow.set_conditional_entry_point(\n",
    "    getEmotions,\n",
    "    {\n",
    "        \"angry\": \"anger_retreival\",\n",
    "        \"depression\": \"depression_retreival\",\n",
    "        \"chatwithagent\": \"chat_with_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"anger_retreival\", \"generate_response\")\n",
    "workflow.add_edge(\"depression_retreival\", \"generate_response\")\n",
    "workflow.add_edge(\n",
    "    \"chat_with_agent\", END\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_response\", check_hallucination,{\n",
    "        \"not useful\": END,\n",
    "        \"chat_with_agent\": \"chat_with_agent\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emotion': 'anxious'}\n",
      "\"Node 'chat_with_agent':\"\n",
      "'\\n---\\n'\n",
      " I'm sorry to hear that you're feeling anxious about your relationship. It's natural to have concerns, but it's important to approach this situation with care for yourself and the relationship. Here are some suggestions:\n",
      "\n",
      "1. Practice mindfulness: Focus on your breath and bring your awareness to the present moment. Try not to let your thoughts spiral into worst-case scenarios.\n",
      "2. Communication: If you feel comfortable, express your concerns to your boyfriend in a calm and non-accusatory way. Open communication can help clarify misunderstandings or address any issues.\n",
      "3. Trust yourself: Trust your instincts and the feelings that arise within you. If something doesn't feel right, it may be worth investigating further.\n",
      "4. Seek support: Reach out to trusted friends or family members for advice and encouragement. Consider seeking professional help if your anxiety is impacting your daily life.\n",
      "5. Focus on what you can control: Instead of dwelling on potential infidelity, focus on the things within your control, such as expressing your feelings and taking care of yourself.\n",
      "6. Practice self-care: Engage in activities that bring you joy and help you relax, like reading, exercising, or practicing a hobby.\n",
      "7. Seek professional help: If your anxiety is impacting your daily life, consider seeking the help of a mental health professional who can provide guidance and support.\n",
      "{'emotion': 'otherwise'}\n",
      "\"Node 'chat_with_agent':\"\n",
      "'\\n---\\n'\n",
      " I'm sorry to hear that you're having trouble sleeping. There are several reasons why this might be happening. Here are some suggestions to help improve your sleep hygiene:\n",
      "\n",
      "1. Establish a consistent bedtime routine: Try going to bed and waking up at the same time every day, even on weekends.\n",
      "2. Create a restful environment: Make sure your bedroom is cool, dark, and quiet. Consider using earplugs, an eye mask, or a white noise machine if needed.\n",
      "3. Avoid screens before bedtime: The blue light emitted by phones, tablets, and computers can interfere with your sleep. Try to avoid screens for at least an hour before bed.\n",
      "4. Limit caffeine intake: Caffeine can disrupt your sleep. Try to avoid consuming it after noon or limit your intake to one or two cups of coffee per day.\n",
      "5. Exercise regularly: Regular physical activity can help improve your sleep quality. Aim for at least 30 minutes of moderate-intensity exercise most days of the week.\n",
      "6. Manage stress: Try relaxation techniques, such as deep breathing, meditation, or progressive muscle relaxation, to help manage stress and promote relaxation before bed.\n",
      "7. Avoid large meals and alcohol before bedtime: Eating large meals or consuming alcohol close to bedtime can disrupt your sleep. Try to finish your last meal of the day at least two hours before bedtime.\n",
      "8. Consider seeking professional help: If you've tried these suggestions and are still having trouble sleeping, consider seeking the help of a healthcare professional who can provide guidance and support.\n",
      "{'emotion': 'anxiety', 'type': 'financial'}\n",
      "\"Node 'chat_with_agent':\"\n",
      "'\\n---\\n'\n",
      " I understand that financial anxiety can be overwhelming and impact your overall well-being. Here are some suggestions to help manage financial stress:\n",
      "\n",
      "1. Create a budget: Identify your income and expenses, and create a realistic budget that allows you to cover your essentials while also saving for emergencies or future goals.\n",
      "2. Prioritize debt repayment: If you have outstanding debts, prioritize paying them off in order of interest rate (highest to lowest). This can help reduce the overall amount of interest you pay over time.\n",
      "3. Build an emergency fund: Aim to save at least three to six months' worth of living expenses in an easily accessible savings account. This can provide a safety net in case of unexpected expenses or income loss.\n",
      "4. Practice mindfulness and gratitude: Focus on the things you have rather than what you don't have. Practicing gratitude and mindfulness can help reduce stress and improve your overall well-being.\n",
      "5. Seek support: Reach out to trusted friends, family members, or financial professionals for advice and encouragement. They may be able to provide valuable insights and resources to help you manage your finances more effectively.\n",
      "6. Practice self-care: Engage in activities that bring you joy and help you relax, such as reading, exercising, or practicing a hobby. Taking care of yourself can help improve your overall well-being and reduce stress.\n",
      "7. Consider seeking professional help: If your financial anxiety is impacting your daily life, consider seeking the help of a mental health professional who can provide guidance and support. They may be able to help you develop coping strategies and improve your overall emotional well-being.\n",
      "{'emotion': 'depression'}\n",
      "\"Node 'depression_retreival':\"\n",
      "'\\n---\\n'\n",
      "{'score': '0'}\n",
      "\"Node 'generate_response':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'chat_with_agent':\"\n",
      "'\\n---\\n'\n",
      " I'm really sorry that you're feeling this way, but I'm unable to provide the help that you need. It's important to reach out to someone who can, though. Reach out to a trusted friend or family member, or contact a mental health professional or crisis hotline in your country as soon as possible. They can provide the support and guidance that you need to help you through this difficult time. Remember, it's okay to ask for help, and there are people who care about you and want to support you.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Run \n",
    "while True:\n",
    "    question = input(\"Enter the question\")\n",
    "    if question.lower() ==\"exit\":\n",
    "        break\n",
    "    inputs = {\"question\": question}\n",
    "    for output in app.stream(inputs):\n",
    "        for key, value in output.items():\n",
    "            pprint(f\"Node '{key}':\")\n",
    "        pprint(\"\\n---\\n\")\n",
    "\n",
    "    print(value[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " I'm really sorry that you're feeling this way, but I'm unable to provide the help that you need. \n",
    "It's important to reach out to someone who can, though. Reach out to a trusted friend or family member, \n",
    "or contact a mental health professional or crisis hotline in your country as soon as possible. They can provide the support and guidance \n",
    "that you need to help you through this difficult time. Remember, \n",
    "it's okay to ask for help, and there are people who care about you and want to support you.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
